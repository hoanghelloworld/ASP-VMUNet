{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c40aa803",
   "metadata": {},
   "source": [
    "# ASP-VMUNet Training for Image Segmentation\n",
    "This notebook trains an ASP-VMUNet model for segmentation tasks. The model is trained using a custom dataset with training, validation, and test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316b1573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image\n",
    "\n",
    "# Adjust path to import modules from the project\n",
    "import sys\n",
    "sys.path.append('./') \n",
    "\n",
    "# Import model and utility functions\n",
    "from models.Atrous.atrous_UL_CNN import atrous_ULPSR_basev3_CNN\n",
    "from utils import save_imgs, get_optimizer, get_scheduler, set_seed, get_logger, cal_params_flops\n",
    "\n",
    "# Set device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838252b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure paths and settings\n",
    "class Config:\n",
    "    # Data paths\n",
    "    data_path = '../data/'  # Path to data folder containing train, val, test\n",
    "    work_dir = '../results/aspvmunet_run/'  # Path to save results\n",
    "    \n",
    "    # Data settings\n",
    "    input_size = 256  # Input image size\n",
    "    train_bs = 8      # Training batch size\n",
    "    val_bs = 4        # Validation batch size\n",
    "    test_bs = 1       # Test batch size\n",
    "    num_workers = 4   # Number of workers for data loading\n",
    "    seed = 42         # Random seed\n",
    "    \n",
    "    # Training settings\n",
    "    epochs = 100       # Number of training epochs\n",
    "    lr = 1e-4          # Learning rate\n",
    "    weight_decay = 1e-4 # Weight decay\n",
    "    val_interval = 1   # Validate every n epochs\n",
    "    save_interval = 10 # Save images every n iterations\n",
    "    print_interval = 10 # Print logs every n iterations\n",
    "    threshold = 0.5    # Threshold for binary segmentation\n",
    "    \n",
    "    # Model configuration\n",
    "    network = 'atrous_UL_CNN'\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer_name = 'AdamW'  # AdamW or SGD\n",
    "    scheduler_name = 'CosineAnnealingLR'\n",
    "    datasets = 'custom'  # Dataset name\n",
    "    gpu_id = 0  # GPU ID\n",
    "    \n",
    "    # Model specific parameters\n",
    "    model_config = {\n",
    "        'num_classes': 1,\n",
    "        'input_channels': 3,\n",
    "        'c_list': [8, 16, 24, 32, 48, 64],\n",
    "        'd_conv': 3,\n",
    "        'split_att': 'fc',\n",
    "        'bridge': True,\n",
    "        'if_shifted_round': False,\n",
    "        'if_ss2d': True,\n",
    "        'forward_type': 'v1',\n",
    "        'encoder_atrous_step': [[2, 2], [2, 2], [2, 2], [2, 2, 2, 2, 2, 2], [2, 2]],\n",
    "        'decoder_atrous_step': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]],\n",
    "        'if_CNN': True,\n",
    "        'if_SE': True,\n",
    "        'if_SK': True,\n",
    "    }\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(config.work_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(config.work_dir, 'log'), exist_ok=True)\n",
    "os.makedirs(os.path.join(config.work_dir, 'checkpoints'), exist_ok=True)\n",
    "os.makedirs(os.path.join(config.work_dir, 'outputs'), exist_ok=True)\n",
    "os.makedirs(os.path.join(config.work_dir, 'test_predictions'), exist_ok=True)\n",
    "\n",
    "# Setup logger and tensorboard writer\n",
    "logger = get_logger('train', os.path.join(config.work_dir, 'log'))\n",
    "writer = SummaryWriter(config.work_dir + 'summary')\n",
    "\n",
    "# Set random seed\n",
    "set_seed(config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf30582",
   "metadata": {},
   "source": [
    "## Create Custom Dataset and DataLoaders\n",
    "We need to create custom datasets to load and preprocess the images and masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec378700",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir=None, transform=None, is_test=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img_dir (string): Directory with all the images.\n",
    "            mask_dir (string, optional): Directory with all the masks.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "            is_test (bool): Whether this is a test dataset (without masks)\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        self.img_names = [f for f in os.listdir(img_dir) if f.endswith('.jpg')]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_names[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.is_test:\n",
    "            # For test data without masks\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, img_name\n",
    "        else:\n",
    "            # For training/validation data with masks\n",
    "            mask_path = os.path.join(self.mask_dir, img_name.replace('.jpg', '.png'))\n",
    "            mask = Image.open(mask_path).convert(\"L\")  # Load as grayscale\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "                mask = self.transform(mask)\n",
    "            \n",
    "            # Normalize mask to 0-1\n",
    "            mask = (mask > 0).float()\n",
    "            \n",
    "            return image, mask\n",
    "\n",
    "# Define transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((config.input_size, config.input_size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((config.input_size, config.input_size)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((config.input_size, config.input_size)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SegmentationDataset(\n",
    "    img_dir=os.path.join(config.data_path, 'train/images'),\n",
    "    mask_dir=os.path.join(config.data_path, 'train/masks'),\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "val_dataset = SegmentationDataset(\n",
    "    img_dir=os.path.join(config.data_path, 'val_images'),\n",
    "    mask_dir=os.path.join(config.data_path, 'val_masks'),\n",
    "    transform=val_transform\n",
    ")\n",
    "\n",
    "test_dataset = SegmentationDataset(\n",
    "    img_dir=os.path.join(config.data_path, 'test/images'),\n",
    "    transform=test_transform,\n",
    "    is_test=True\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.train_bs,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=config.num_workers\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.val_bs,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=config.num_workers\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config.test_bs,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=config.num_workers\n",
    ")\n",
    "\n",
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of validation samples: {len(val_dataset)}\")\n",
    "print(f\"Number of test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d35b76b",
   "metadata": {},
   "source": [
    "## Initialize the Model, Loss Function, Optimizer, and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eafac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = atrous_ULPSR_basev3_CNN(\n",
    "    num_classes=config.model_config['num_classes'],\n",
    "    input_channels=config.model_config['input_channels'],\n",
    "    c_list=config.model_config['c_list'],\n",
    "    d_conv=config.model_config['d_conv'],\n",
    "    split_att=config.model_config['split_att'],\n",
    "    bridge=config.model_config['bridge'],\n",
    "    if_shifted_round=config.model_config['if_shifted_round'],\n",
    "    if_ss2d=config.model_config['if_ss2d'],\n",
    "    forward_type=config.model_config['forward_type'],\n",
    "    encoder_atrous_step=config.model_config['encoder_atrous_step'],\n",
    "    decoder_atrous_step=config.model_config['decoder_atrous_step'],\n",
    "    if_CNN=config.model_config['if_CNN'],\n",
    "    if_SE=config.model_config['if_SE'],\n",
    "    if_SK=config.model_config['if_SK'],\n",
    ")\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Display model size and FLOPS\n",
    "cal_params_flops(copy.deepcopy(model), config.input_size, logger)\n",
    "\n",
    "# Define loss function, optimizer, and scheduler\n",
    "criterion = config.criterion\n",
    "optimizer = get_optimizer(config, model)\n",
    "scheduler = get_scheduler(config, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4295ad",
   "metadata": {},
   "source": [
    "## Training and Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b110d380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(loader, model, criterion, optimizer, scheduler, epoch, step, logger, config, writer):\n",
    "    \"\"\"Train model for one epoch\"\"\"\n",
    "    model.train()\n",
    "    loss_list = []\n",
    "    \n",
    "    for iter, (images, masks) in enumerate(loader):\n",
    "        step += 1\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        images = images.to(device).float()\n",
    "        masks = masks.to(device).float()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_list.append(loss.item())\n",
    "        now_lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "        \n",
    "        writer.add_scalar('loss', loss, global_step=step)\n",
    "        \n",
    "        if iter % config.print_interval == 0:\n",
    "            log_info = f'train: epoch {epoch}, iter:{iter}, loss: {np.mean(loss_list):.4f}, lr: {now_lr}'\n",
    "            print(log_info)\n",
    "            logger.info(log_info)\n",
    "            \n",
    "    scheduler.step()\n",
    "    return step\n",
    "\n",
    "def val_one_epoch(loader, model, criterion, epoch, logger, config):\n",
    "    \"\"\"Evaluate model on validation data\"\"\"\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    gts = []\n",
    "    loss_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img, msk in tqdm(loader):\n",
    "            img = img.to(device).float()\n",
    "            msk = msk.to(device).float()\n",
    "            \n",
    "            out = model(img)\n",
    "            loss = criterion(out, msk)\n",
    "            \n",
    "            loss_list.append(loss.item())\n",
    "            gts.append(msk.squeeze(1).cpu().detach().numpy())\n",
    "            out = out.squeeze(1).cpu().detach().numpy()\n",
    "            preds.append(out)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    if epoch % config.val_interval == 0:\n",
    "        preds = np.concatenate([p.flatten() for p in preds])\n",
    "        gts = np.concatenate([g.flatten() for g in gts])\n",
    "        \n",
    "        y_pre = np.where(preds >= config.threshold, 1, 0)\n",
    "        y_true = np.where(gts >= 0.5, 1, 0)\n",
    "        \n",
    "        confusion = confusion_matrix(y_true, y_pre)\n",
    "        TN, FP, FN, TP = confusion[0,0], confusion[0,1], confusion[1,0], confusion[1,1]\n",
    "        \n",
    "        accuracy = float(TN + TP) / float(np.sum(confusion)) if float(np.sum(confusion)) != 0 else 0\n",
    "        sensitivity = float(TP) / float(TP + FN) if float(TP + FN) != 0 else 0\n",
    "        specificity = float(TN) / float(TN + FP) if float(TN + FP) != 0 else 0\n",
    "        f1_or_dsc = float(2 * TP) / float(2 * TP + FP + FN) if float(2 * TP + FP + FN) != 0 else 0\n",
    "        miou = float(TP) / float(TP + FP + FN) if float(TP + FP + FN) != 0 else 0\n",
    "        \n",
    "        log_info = f' val epoch: {epoch}, loss: {np.mean(loss_list):.4f}, miou: {miou:.4f}, f1_or_dsc: {f1_or_dsc:.4f}, accuracy: {accuracy:.4f}, \\\n",
    "                specificity: {specificity:.4f}, sensitivity: {sensitivity:.4f}, confusion_matrix: {confusion}'\n",
    "        print(log_info)\n",
    "        logger.info(log_info)\n",
    "    else:\n",
    "        log_info = f' val epoch: {epoch}, loss: {np.mean(loss_list):.4f}'\n",
    "        print(log_info)\n",
    "        logger.info(log_info)\n",
    "    \n",
    "    return np.mean(loss_list), f1_or_dsc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec11d417",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c575fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "min_loss = 999\n",
    "max_dsc = -1\n",
    "start_epoch = 1\n",
    "min_epoch = 1\n",
    "step = 0\n",
    "\n",
    "# Resume from checkpoint if exists\n",
    "resume_model = os.path.join(config.work_dir, 'checkpoints', 'latest.pth')\n",
    "if os.path.exists(resume_model):\n",
    "    print('#----------Resume Model and Other params----------#')\n",
    "    checkpoint = torch.load(resume_model, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    saved_epoch = checkpoint['epoch']\n",
    "    start_epoch = saved_epoch + 1\n",
    "    min_loss, min_epoch, loss, max_dsc = checkpoint['min_loss'], checkpoint['min_epoch'], checkpoint['loss'], checkpoint['max_dsc']\n",
    "    \n",
    "    log_info = f'Resuming model from {resume_model}. resume_epoch: {saved_epoch}, min_loss: {min_loss:.4f}, min_epoch: {min_epoch}, max_dsc: {max_dsc:.4f}'\n",
    "    print(log_info)\n",
    "    logger.info(log_info)\n",
    "\n",
    "print('#----------Training Started----------#')\n",
    "for epoch in range(start_epoch, config.epochs + 1):\n",
    "    t = time.time()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Train for one epoch\n",
    "    step = train_one_epoch(\n",
    "        train_loader,\n",
    "        model,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        epoch,\n",
    "        step,\n",
    "        logger,\n",
    "        config,\n",
    "        writer\n",
    "    )\n",
    "    print(f'Training time: {time.time() - t:.2f}s')\n",
    "    \n",
    "    # Validate\n",
    "    loss, dsc = val_one_epoch(\n",
    "        val_loader,\n",
    "        model,\n",
    "        criterion,\n",
    "        epoch,\n",
    "        logger,\n",
    "        config\n",
    "    )\n",
    "    print(f'Total epoch time: {time.time() - t:.2f}s')\n",
    "    \n",
    "    # Save best model\n",
    "    if dsc > max_dsc:\n",
    "        torch.save(model.state_dict(), os.path.join(config.work_dir, 'checkpoints', 'best.pth'))\n",
    "        min_loss = loss\n",
    "        min_epoch = epoch\n",
    "        max_dsc = dsc\n",
    "        \n",
    "    print(f'Best model at epoch {min_epoch} with DSC {max_dsc:.4f}')\n",
    "    \n",
    "    # Save latest model\n",
    "    torch.save(\n",
    "        {\n",
    "            'epoch': epoch,\n",
    "            'min_loss': min_loss,\n",
    "            'min_epoch': min_epoch,\n",
    "            'loss': loss,\n",
    "            'max_dsc': max_dsc,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "        }, os.path.join(config.work_dir, 'checkpoints', 'latest.pth')\n",
    "    )\n",
    "\n",
    "print('#----------Training Completed----------#')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a30f48c",
   "metadata": {},
   "source": [
    "## Test and Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c8c7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction_mask(mask, filename, save_path):\n",
    "    \"\"\"Save the predicted mask as a PNG file\"\"\"\n",
    "    # Convert to binary mask (0-255)\n",
    "    binary_mask = (mask > config.threshold).astype(np.uint8) * 255\n",
    "    # Save as PNG\n",
    "    Image.fromarray(binary_mask).save(os.path.join(save_path, filename))\n",
    "\n",
    "# Load best model for testing\n",
    "print('#----------Testing----------#')\n",
    "best_model_path = os.path.join(config.work_dir, 'checkpoints', 'best.pth')\n",
    "if os.path.exists(best_model_path):\n",
    "    best_weight = torch.load(best_model_path, map_location=device)\n",
    "    model.load_state_dict(best_weight)\n",
    "    model.eval()\n",
    "    \n",
    "    # Create directory for saving predictions\n",
    "    prediction_dir = os.path.join(config.work_dir, 'test_predictions')\n",
    "    os.makedirs(prediction_dir, exist_ok=True)\n",
    "    \n",
    "    # Generate and save predictions\n",
    "    with torch.no_grad():\n",
    "        for i, (img, img_name) in enumerate(tqdm(test_loader)):\n",
    "            img = img.to(device).float()\n",
    "            out = model(img)\n",
    "            \n",
    "            # Convert output to numpy\n",
    "            pred_mask = out.squeeze().cpu().numpy()\n",
    "            \n",
    "            # Save prediction\n",
    "            save_prediction_mask(pred_mask, img_name[0].replace('.jpg', '.png'), prediction_dir)\n",
    "            \n",
    "            # Optionally visualize some predictions\n",
    "            if i % config.save_interval == 0:\n",
    "                plt.figure(figsize=(10, 5))\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.imshow(img.squeeze().permute(1, 2, 0).cpu().numpy())\n",
    "                plt.title('Original Image')\n",
    "                plt.axis('off')\n",
    "                \n",
    "                plt.subplot(1, 2, 2)\n",
    "                plt.imshow(pred_mask, cmap='gray')\n",
    "                plt.title('Predicted Mask')\n",
    "                plt.axis('off')\n",
    "                \n",
    "                plt.savefig(os.path.join(config.work_dir, 'outputs', f'test_prediction_{i}.png'))\n",
    "                plt.close()\n",
    "    \n",
    "    print(f\"Predictions saved to {prediction_dir}\")\n",
    "else:\n",
    "    print(\"Best model not found. Cannot generate predictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55c64bd",
   "metadata": {},
   "source": [
    "## Analyze Results\n",
    "\n",
    "After generating predictions, you can analyze the results:\n",
    "\n",
    "1. **Visualize some predictions**: Review the images saved in the outputs directory to see how well your model is performing.\n",
    "2. **Prepare Kaggle submission**: The predictions saved in the `test_predictions` folder are ready to be submitted to Kaggle.\n",
    "3. **Evaluate model metrics**: Review the validation metrics from the training process to understand the model's performance."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
